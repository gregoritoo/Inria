{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on importe les librairies \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import os\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential,Model \n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,Input\n",
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on active tensorflow-gpu (uniquement si votre pc a un GPU+cuda+cudnn) et on alloue 70% du gpu à tensorflow (pour eviter les overflows)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on prépare les structures de données qui vont accuellir les séries temporelles et le numéro des classes que l'on one hot encode \n",
    "classes = os.listdir(\"../classes\")\n",
    "one_hot_vector = np.zeros((1,len(classes)))\n",
    "\n",
    "train_data_x = np.zeros((max_size,180,basewidth,3))\n",
    "train_data_y = np.zeros((max_size,len(classes)))\n",
    "\n",
    "test_data_x = np.zeros((max_size,180,basewidth,3))\n",
    "test_data_y = np.zeros((max_size,len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on va créer notre base d'entrainement en conservant la même proportion d'individues dans les classes \n",
    "# que dans la base entière et on n'utilise pas les données augmentées pour les test\n",
    "count_training = 0\n",
    "count_test = 0\n",
    "vec = []\n",
    "for class_element in classes :\n",
    "    i = int(class_element.replace(\"class_\",\"\")) - 1\n",
    "    print(i)\n",
    "    images = os.listdir(\"../classes/\"+class_element+\"/spectro/\")\n",
    "    split_train = int(0.7*len(images))\n",
    "    split_test = len(images)-split_train\n",
    "    part_counter = 0\n",
    "    print(\"==========================================================\")\n",
    "    for image in images :\n",
    "        print(image)\n",
    "        if image[0] != \"a\" :\n",
    "            img = Image.open(\"../classes/\"+class_element+\"/spectro/\"+image)\n",
    "            img.load()\n",
    "            img = img.convert('RGB')\n",
    "            wpercent = (basewidth/float(img.size[0]))\n",
    "            hsize = 180\n",
    "            img = img.resize((240,hsize), Image.ANTIALIAS)\n",
    "            data = np.asarray(img, dtype=\"float32\")\n",
    "            if part_counter < split_train :\n",
    "                train_data_x[count_training,:,:,:] = data \n",
    "                train_data_y[count_training,i] = 1 \n",
    "                count_training = count_training + 1\n",
    "                part_counter = part_counter + 1\n",
    "                list_augment = os.listdir(\"../classes/\"+class_element+'/spectro/augment/')\n",
    "                print(\"==========================================================\")\n",
    "                for spec in list_augment :\n",
    "                    try :\n",
    "                        if  int(spec[:3]) == int(image.replace(\".png\",\"\")) :\n",
    "                            print(spec)\n",
    "                            img = Image.open(\"../classes/\"+class_element+\"/spectro/augment/\"+spec)\n",
    "                            img.load()\n",
    "                            img = img.convert('RGB')\n",
    "                            wpercent = (basewidth/float(img.size[0]))\n",
    "                            hsize = 180\n",
    "                            img = img.resize((240,hsize), Image.ANTIALIAS)\n",
    "                            data = np.asarray(img, dtype=\"float32\")\n",
    "                            train_data_x[count_training,:,:,:] = data \n",
    "                            train_data_y[count_training,i] = 1 \n",
    "                            count_training = count_training + 1\n",
    "                        else :\n",
    "                            pass\n",
    "                    except Exception as e :\n",
    "                        try :\n",
    "                            if  int(spec[:2]) == int(image.replace(\".png\",\"\")) :\n",
    "                                print(spec)\n",
    "                                img = Image.open(\"../classes/\"+class_element+\"/spectro/augment/\"+spec)\n",
    "                                img.load()\n",
    "                                img = img.convert('RGB')\n",
    "                                wpercent = (basewidth/float(img.size[0]))\n",
    "                                hsize = 180\n",
    "                                img = img.resize((240,hsize), Image.ANTIALIAS)\n",
    "                                data = np.asarray(img, dtype=\"float32\")\n",
    "                                train_data_x[count_training,:,:,:] = data \n",
    "                                train_data_y[count_training,i] = 1 \n",
    "                                count_training = count_training + 1\n",
    "                        except Exception as e :\n",
    "                            if  int(spec[:1]) == int(image.replace(\".png\",\"\")) :\n",
    "                                print(spec)\n",
    "                                img = Image.open(\"../classes/\"+class_element+\"/spectro/augment/\"+spec)\n",
    "                                img.load()\n",
    "                                img = img.convert('RGB')\n",
    "                                wpercent = (basewidth/float(img.size[0]))\n",
    "                                hsize = 180\n",
    "                                img = img.resize((240,hsize), Image.ANTIALIAS)\n",
    "                                data = np.asarray(img, dtype=\"float32\")\n",
    "                                train_data_x[count_training,:,:,:] = data \n",
    "                                train_data_y[count_training,i] = 1 \n",
    "                                count_training = count_t\n",
    "            else :\n",
    "                test_data_x[count_test,:,:,:] = data \n",
    "                test_data_y[count_test,i] = 1 \n",
    "                count_test = count_test + 1\n",
    "                vec.append(int(image.replace(\".png\",\"\")))\n",
    "                \n",
    "                \n",
    "train_data_x = train_data_x[: count_training,:,:,:]\n",
    "train_data_y = train_data_y[: count_training,:]\n",
    "\n",
    "test_data_x = test_data_x[: count_test,:,:,:]\n",
    "test_data_y = test_data_y[: count_test,:]\n",
    "\n",
    "# on sauvegarde \n",
    "with open('train_data_x.npy', 'wb') as f:\n",
    "    np.save(f, train_data_x)\n",
    "\n",
    "with open('train_data_y.npy', 'wb') as f1:\n",
    "    np.save(f1, train_data_y)\n",
    "\n",
    "with open('test_data_x.npy', 'wb') as f2:\n",
    "    np.save(f2, test_data_x)\n",
    "\n",
    "with open('test_data_y.npy', 'wb') as f3:\n",
    "    np.save(f3, test_data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on reload les données puis on les normalises \n",
    "train_data_y = np.load(\"./train_data_y.npy\").astype('float32')\n",
    "train_data_x = np.load(\"./train_data_x.npy\").astype('float32')\n",
    "train_data_x /= 255 \n",
    "test_data_x = np.load(\"./test_data_x.npy\").astype('float32')\n",
    "test_data_x /= 255\n",
    "test_data_y = np.load(\"./test_data_y.npy\").astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée notre modèle (transfert learning à partir d'inceptionV3 entrainé sur imagenet)\n",
    "input=Input(shape=(180, 240, 3))\n",
    "classifier = InceptionV3(include_top=False ,weights='imagenet')(input)\n",
    "top_model = Flatten()(classifier)\n",
    "top_model = Dense(2046,activation=\"relu\") (top_model)\n",
    "top_model = Dense(1024,activation=\"relu\") (top_model)\n",
    "top_model = Dense(512,activation=\"relu\") (top_model)\n",
    "output = Dense(18,activation='softmax') (top_model)\n",
    "classifier=Model(input,output)\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on l'entraine puis on l'évalue \n",
    "classifier.fit(train_data_x, train_data_y,\n",
    "                    batch_size=7,\n",
    "                    epochs=17)\n",
    "\n",
    "results = classifier.evaluate(test_data_x, test_data_y, batch_size=7)\n",
    "print('test loss, test acc:', results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sauvegarde du modele\n",
    "classifier.save('model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
